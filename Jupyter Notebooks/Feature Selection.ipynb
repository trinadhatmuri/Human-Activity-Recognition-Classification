{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ded7f4",
   "metadata": {},
   "source": [
    "<center><h1>Modelling</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce1f70",
   "metadata": {},
   "source": [
    "<h2>Importing Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532c5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76bac6d",
   "metadata": {},
   "source": [
    "<h2>Importing Feature sets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9dc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../Processed Data/All Features/X_train.csv\")\n",
    "X_test = pd.read_csv(\"../Processed Data/All Features/X_test.csv\")\n",
    "Y_train = pd.read_csv(\"../Processed Data/All Features/Y_train.csv\")\n",
    "Y_test = pd.read_csv(\"../Processed Data/All Features/Y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55e7e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Y_train[\"activity_code\"] - 1\n",
    "y_test = Y_test[\"activity_code\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e831389d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    537\n",
       "4    532\n",
       "0    496\n",
       "3    491\n",
       "1    471\n",
       "2    420\n",
       "Name: activity_code, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c0f87",
   "metadata": {},
   "source": [
    "<h2>Cross Validation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ada388",
   "metadata": {},
   "source": [
    "It is generally a good idea to have a validation set, so we can test our model performance on validation and see if there is something we need to do. But having one split may result in depending solely on a single set, which might have unforseen consequesnces. So that is why instead of just 1 we have multiple splits, on the training set, in a training size /  number of folds (or) sets ratio, wo that we can have multiple validation sets while the remaining sets are used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b6c9b",
   "metadata": {},
   "source": [
    "We are going to be using StratifiegKFold for splitting our training data into 5 sets of training and validation data. Stratified preserves the class distribution which comes handy with Imbalanced datasets. Althought our dataset is not severely imbalanced, it serves the purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eae338c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539137d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\" : rf_model,\n",
    "    \"XGBoost\" : xgb_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6150c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    \"All features\" : (X_train, y_train)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27e0d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performs k-fold cross-validation for each model on each feature set and aggregates the results.\n",
    "\n",
    "Args:\n",
    "    models (dict): Format: { 'model_name': model_instance }\n",
    "    feature_sets (dict): Format: { 'feature_set_name': (X_train, y_train) }\n",
    "\n",
    "Returns:\n",
    "    dict: A nested dictionary containing raw cross_validate results for each model-feature set combination.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def calculate_cross_validation_scores(models, feature_sets):\n",
    "    \n",
    "    model_scores = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        for feature_name, (X_train, y_train) in feature_sets.items():\n",
    "            print(f\"\\nScore for {model_name} and the feature set {feature_name}\\n\")\n",
    "            \n",
    "            cv_scores = cross_validate(model, X_train, y_train, cv=skf, scoring=['accuracy', 'f1_macro'])\n",
    "\n",
    "            model_feature_name = model_name + \" \" + feature_name\n",
    "            \n",
    "            if model_feature_name not in model_scores.keys():\n",
    "                model_scores[model_feature_name] = cv_scores\n",
    "\n",
    "            mean_accuracy = cv_scores['test_accuracy'].mean()\n",
    "            std_accuracy = cv_scores['test_accuracy'].std()\n",
    "            f1_macro = cv_scores['test_f1_macro'].mean()\n",
    "            f1_macro_std = cv_scores['test_f1_macro'].std()\n",
    "\n",
    "            print(f\"Mean accuracy across 5 folds is {mean_accuracy:.3f}\")\n",
    "            print(f\"Standard Deviation in accuracy across 5 folds is {std_accuracy:.3f}\")\n",
    "            print(f\"Mean f1_macro across 5 folds is {f1_macro:.3f}\")\n",
    "            print(f\"Standard Deviation in f1_macro across 5 folds is {f1_macro_std:.3f}\") \n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bb52945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for Random Forest and the feature set All features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.982\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.982\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for XGBoost and the feature set All features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.991\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.992\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n"
     ]
    }
   ],
   "source": [
    "scores = calculate_cross_validation_scores(models, feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8b4aaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest All features': {'fit_time': array([4.71441412, 1.19176006, 1.38288283, 1.19029713, 1.20343184]),\n",
       "  'score_time': array([0.02812099, 0.02442789, 0.01977324, 0.02151394, 0.02130103]),\n",
       "  'test_accuracy': array([0.9789259 , 0.98300476, 0.97959184, 0.9829932 , 0.98367347]),\n",
       "  'test_f1_macro': array([0.97904515, 0.98304675, 0.97966997, 0.98291896, 0.98448599])},\n",
       " 'XGBoost All features': {'fit_time': array([5.30612469, 5.26603103, 5.31443477, 5.21232986, 5.43376279]),\n",
       "  'score_time': array([0.04024911, 0.03685904, 0.04674101, 0.03651094, 0.04222679]),\n",
       "  'test_accuracy': array([0.98844324, 0.99184228, 0.99319728, 0.99115646, 0.99251701]),\n",
       "  'test_f1_macro': array([0.98844554, 0.99218359, 0.99331957, 0.99140177, 0.99278015])}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9699d",
   "metadata": {},
   "source": [
    "<h2>Model Efficency</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd494a85",
   "metadata": {},
   "source": [
    "Efficency can be determined as performance per feature. The scores can be interpreted as follows:\n",
    "<ul>\n",
    "    <li><b>High Efficiency:</b> Greater than 2.0</li>\n",
    "    <li><b>Good Efficency:</b> 1.5 - 2.0</li>\n",
    "    <li><b>Moderate Efficency:</b> 1.0-1.5</li>\n",
    "    <li><b>Low Efficency:</b>  Less than 1.0</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0e7750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculates a model efficiency metric for each experiment by combining predictive performance\n",
    "with feature set economy.\n",
    "\n",
    "Args:\n",
    "    scores (dict): A dictionary where keys are experiment names and values are dictionaries\n",
    "                   containing 'test_accuracy' and 'test_f1_macro' score arrays.\n",
    "    feature_sets (dict): A dictionary where keys are feature set names and values are tuples\n",
    "                         containing (feature_matrix, target_vector).\n",
    "\n",
    "Returns:\n",
    "    dict: A dictionary where keys are experiment names and values are the calculated efficiency score.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def evaluate_model_efficiency(scores, feature_sets):\n",
    "    \n",
    "    efficiencies = {}\n",
    "    \n",
    "    for experiment, score in scores.items():\n",
    "\n",
    "        accuracy = score['test_accuracy'].mean()\n",
    "        f1_macro = score['test_f1_macro'].mean()\n",
    "        \n",
    "        num_features = 0\n",
    " \n",
    "        for feature_name in feature_sets.keys():\n",
    "            if feature_name in experiment:\n",
    "                \n",
    "                num_features = feature_sets[feature_name][0].shape[1]\n",
    "                break\n",
    "\n",
    "        efficiency = (accuracy * f1_macro * 1000) / num_features\n",
    "        \n",
    "        print(f\"Efficency per feature for {experiment} is {efficiency:.2f}\")\n",
    "        \n",
    "        efficiencies[experiment] = efficiency\n",
    "    return efficiencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97edae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficency per feature for Random Forest All features is 1.72\n",
      "Efficency per feature for XGBoost All features is 1.75\n"
     ]
    }
   ],
   "source": [
    "efficiencies = evaluate_model_efficiency(scores, feature_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f765af",
   "metadata": {},
   "source": [
    "<h2>Feature set on Random Forest Feature Importance</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "849f1168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b299aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_importances = rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "015a928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "057f6483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 important features are\n",
      "\n",
      "                       feature  importance\n",
      "40     tGravityAcc-mean()-X_40    0.036380\n",
      "49      tGravityAcc-max()-X_49    0.030331\n",
      "558   angle(X,gravityMean)_558    0.029676\n",
      "41     tGravityAcc-mean()-Y_41    0.025355\n",
      "56   tGravityAcc-energy()-X_56    0.024963\n",
      "559   angle(Y,gravityMean)_559    0.024415\n",
      "52      tGravityAcc-min()-X_52    0.022650\n",
      "50      tGravityAcc-max()-Y_50    0.021705\n",
      "53      tGravityAcc-min()-Y_53    0.021635\n",
      "57   tGravityAcc-energy()-Y_57    0.017179\n"
     ]
    }
   ],
   "source": [
    "rf_importance_df = pd.DataFrame({\n",
    "    \"feature\" : feature_names,\n",
    "    \"importance\" : rf_feature_importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"Top 10 important features are\\n\")\n",
    "print(rf_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b97c2",
   "metadata": {},
   "source": [
    "<b>The total of importance for all the feature combined should be equal to 1.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699e5dc",
   "metadata": {},
   "source": [
    "<h2>Highly co-related Features Removal</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864f551",
   "metadata": {},
   "source": [
    "Since the second phase of our goal is to remove one of the two highly related features based on the correlation threshold, we need to have a function to do it a number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bf9b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(X_data, feature_names, feature_importances, threshold):\n",
    "    \n",
    "    \"\"\"\n",
    "   Removes highly correlated features while preserving those with highest importance scores.\n",
    "   \n",
    "   Args:\n",
    "       X_data: Feature matrix for correlation calculation\n",
    "       feature_names: List of feature column names\n",
    "       feature_importances: DataFrame with feature importance scores\n",
    "       threshold: Correlation threshold above which features are considered redundant\n",
    "       \n",
    "   Returns:\n",
    "       set: Feature names to be removed from the dataset\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    corr_series = X_data.corr()\n",
    "    \n",
    "    features_to_remove = set()\n",
    "    \n",
    "    for feature1 in feature_names:\n",
    "        if feature1 in features_to_remove:\n",
    "            continue\n",
    "            \n",
    "        highly_correlated = []\n",
    "        for feature2 in feature_names:\n",
    "            if feature1 != feature2 and feature2 not in features_to_remove:\n",
    "                try:\n",
    "                    corr_value = corr_series.loc[feature1, feature2]\n",
    "                except KeyError:\n",
    "                    corr_value = corr_series.loc[feature2, feature1]\n",
    "                if corr_value > threshold:\n",
    "                    highly_correlated.append(feature2)\n",
    "                    \n",
    "        for feature2 in highly_correlated:\n",
    "            f1 = feature_importances[feature_importances['feature'] == feature1].values[0][1]\n",
    "            f2 = feature_importances[feature_importances['feature'] == feature2].values[0][1]\n",
    "            \n",
    "            if f1 < f2:\n",
    "                features_to_remove.add(feature1)\n",
    "            else:\n",
    "                features_to_remove.add(feature2)\n",
    "                \n",
    "    return features_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ffce111",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = remove_correlated_features(X_train, feature_names, rf_importance_df, 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2998c074",
   "metadata": {},
   "source": [
    "After knowing what features to remove, we have to filter out the features to be removed from the existing importance feature set to get the final feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df267d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_set(X_data, importance_df, top_n_features, correlation_threshold):\n",
    "    \"\"\"\n",
    "    Creates optimized feature set by selecting top-N important features and removing correlations.\n",
    "   \n",
    "   Args:\n",
    "       X_data: Input feature matrix\n",
    "       importance_df: DataFrame containing feature importance scores sorted in descending order\n",
    "       top_n_features: Number of top features to select based on importance\n",
    "       correlation_threshold: Correlation threshold for feature removal\n",
    "       \n",
    "   Returns:\n",
    "       DataFrame: Filtered feature set with reduced dimensionality and multicollinearity\n",
    "   \"\"\"\n",
    "    \n",
    "    important_features = X_data[importance_df['feature'][:top_n_features]]\n",
    "    \n",
    "    filtered_importance_df = importance_df[importance_df['feature'].isin(important_features.columns)] \n",
    "    \n",
    "    features_to_remove = remove_correlated_features(important_features, important_features.columns, \n",
    "                                                    filtered_importance_df, correlation_threshold)\n",
    "    \n",
    "    final_feature_set = important_features.drop(list(features_to_remove), axis=1)\n",
    "    \n",
    "    return final_feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cf8de",
   "metadata": {},
   "source": [
    "<h2>Creating Feature Sets</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e22a7",
   "metadata": {},
   "source": [
    "We are going to use multiple choices for both the number of features and correlation thresholds, so we get multiple different feature sets, we can choose from based on their accuracy and f1_macro scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6cd8185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF feature count 80 correlation threshold 0.85 reduced to 25 features\n",
      "RF feature count 80 correlation threshold 0.9 reduced to 26 features\n",
      "RF feature count 80 correlation threshold 0.95 reduced to 33 features\n",
      "RF feature count 100 correlation threshold 0.85 reduced to 34 features\n",
      "RF feature count 100 correlation threshold 0.9 reduced to 36 features\n",
      "RF feature count 100 correlation threshold 0.95 reduced to 43 features\n",
      "RF feature count 120 correlation threshold 0.85 reduced to 37 features\n",
      "RF feature count 120 correlation threshold 0.9 reduced to 39 features\n",
      "RF feature count 120 correlation threshold 0.95 reduced to 47 features\n"
     ]
    }
   ],
   "source": [
    "feature_counts = [80, 100, 120]\n",
    "correlation_thresholds = [0.85, 0.90, 0.95]\n",
    "\n",
    "rf_feature_sets = {}\n",
    "\n",
    "for count in feature_counts:\n",
    "    for threshold in correlation_thresholds:\n",
    "        feature_set = create_feature_set(X_train, rf_importance_df, count, threshold)\n",
    "        identifying_string = \"RF feature count \" + str(count) + \" correlation threshold \" + str(threshold)\n",
    "        rf_feature_sets[identifying_string] = feature_set\n",
    "        print(f\"{identifying_string} reduced to {feature_set.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372dec09",
   "metadata": {},
   "source": [
    "<b>Let us go ahead and arrange them in a dictionary, so it is easy to access when we want to work on them.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "207537bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_feature_sets = {}\n",
    "for id_string, feature_set in rf_feature_sets.items():\n",
    "    random_forest_feature_sets[id_string] = (feature_set, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd51f4e",
   "metadata": {},
   "source": [
    "<h2>XGBoost Feature Importance</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ca821",
   "metadata": {},
   "source": [
    "Just as we made different feature sets based on feature importance and correlation removal based Random Forest, we are going to do the same for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb689ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a96b6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_feature_importances = xgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20eecb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 feature  importance\n",
      "330       fBodyAcc-bandsEnergy()-1,8_330    0.072055\n",
      "52                tGravityAcc-min()-X_52    0.063094\n",
      "296            fBodyAcc-skewness()-X_296    0.046372\n",
      "410  fBodyAccJerk-bandsEnergy()-9,16_410    0.039299\n",
      "201                tBodyAccMag-std()_201    0.037172\n"
     ]
    }
   ],
   "source": [
    "xgb_importance_df = pd.DataFrame({\n",
    "    \"feature\" : feature_names,\n",
    "    \"importance\" : xgb_feature_importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(xgb_importance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50fd38d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB feature count 80 correlation threshold 0.85 reduced to 37 features\n",
      "XGB feature count 80 correlation threshold 0.9 reduced to 45 features\n",
      "XGB feature count 80 correlation threshold 0.95 reduced to 53 features\n",
      "XGB feature count 100 correlation threshold 0.85 reduced to 46 features\n",
      "XGB feature count 100 correlation threshold 0.9 reduced to 53 features\n",
      "XGB feature count 100 correlation threshold 0.95 reduced to 65 features\n",
      "XGB feature count 120 correlation threshold 0.85 reduced to 54 features\n",
      "XGB feature count 120 correlation threshold 0.9 reduced to 61 features\n",
      "XGB feature count 120 correlation threshold 0.95 reduced to 75 features\n"
     ]
    }
   ],
   "source": [
    "xgb_feature_sets = {}\n",
    "\n",
    "for count in feature_counts:\n",
    "    for threshold in correlation_thresholds:\n",
    "        feature_set = create_feature_set(X_train, xgb_importance_df, count, threshold)\n",
    "        identifying_string = \"XGB feature count \" + str(count) + \" correlation threshold \" + str(threshold)\n",
    "        xgb_feature_sets[identifying_string] = feature_set\n",
    "        print(f\"{identifying_string} reduced to {feature_set.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b8db87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_feature_sets = {}\n",
    "for id_string, feature_set in xgb_feature_sets.items():\n",
    "    xgboost_feature_sets[id_string] = (feature_set, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec8480",
   "metadata": {},
   "source": [
    "<h2> Importing other Feature Sets</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3e842",
   "metadata": {},
   "source": [
    "We got two other feature sets we have from the preprocessing dictionary, which we are going to be evaluating in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5becf40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_anova_60 = pd.read_csv(\"../Processed Data/ANOVA hybrid set/X_train_anova_filtered_60.csv\")\n",
    "X_test_anova_60 = pd.read_csv(\"../Processed Data/ANOVA hybrid set/X_test_anova_filtered_60.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91dda31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mean_std = pd.read_csv(\"../Processed Data/Mean Features/feature_reduced_X_train.csv\")\n",
    "X_test_mean_std = pd.read_csv(\"../Processed Data/Mean Features/feature_reduced_X_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fb9d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_feature_sets = {\n",
    "    \"anova_60\" : (X_train_anova_60, y_train),\n",
    "    \"mean_std\" : (X_train_mean_std, y_train)\n",
    "}\n",
    "\n",
    "feature_sets.update(other_feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1071036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for Random Forest and the feature set RF feature count 80 correlation threshold 0.85\n",
      "\n",
      "Mean accuracy across 5 folds is 0.978\n",
      "Standard Deviation in accuracy across 5 folds is 0.003\n",
      "Mean f1_macro across 5 folds is 0.978\n",
      "Standard Deviation in f1_macro across 5 folds is 0.003\n",
      "\n",
      "Score for Random Forest and the feature set RF feature count 80 correlation threshold 0.9\n",
      "\n",
      "Mean accuracy across 5 folds is 0.978\n",
      "Standard Deviation in accuracy across 5 folds is 0.003\n",
      "Mean f1_macro across 5 folds is 0.978\n",
      "Standard Deviation in f1_macro across 5 folds is 0.003\n",
      "\n",
      "Score for Random Forest and the feature set RF feature count 80 correlation threshold 0.95\n",
      "\n",
      "Mean accuracy across 5 folds is 0.980\n",
      "Standard Deviation in accuracy across 5 folds is 0.003\n",
      "Mean f1_macro across 5 folds is 0.980\n",
      "Standard Deviation in f1_macro across 5 folds is 0.003\n",
      "\n",
      "Score for Random Forest and the feature set RF feature count 100 correlation threshold 0.85\n",
      "\n",
      "Mean accuracy across 5 folds is 0.979\n",
      "Standard Deviation in accuracy across 5 folds is 0.005\n",
      "Mean f1_macro across 5 folds is 0.979\n",
      "Standard Deviation in f1_macro across 5 folds is 0.005\n",
      "\n",
      "Score for Random Forest and the feature set RF feature count 100 correlation threshold 0.9\n",
      "\n",
      "Mean accuracy across 5 folds is 0.980\n",
      "Standard Deviation in accuracy across 5 folds is 0.005\n",
      "Mean f1_macro across 5 folds is 0.981\n",
      "Standard Deviation in f1_macro across 5 folds is 0.005\n",
      "\n",
      "Score for Random Forest and the feature set RF feature count 100 correlation threshold 0.95\n",
      "\n",
      "Mean accuracy across 5 folds is 0.980\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.980\n",
      "Standard Deviation in f1_macro across 5 folds is 0.003\n",
      "\n",
      "Score for Random Forest and the feature set RF feature count 120 correlation threshold 0.85\n",
      "\n",
      "Mean accuracy across 5 folds is 0.979\n",
      "Standard Deviation in accuracy across 5 folds is 0.004\n",
      "Mean f1_macro across 5 folds is 0.980\n",
      "Standard Deviation in f1_macro across 5 folds is 0.004\n",
      "\n",
      "Score for Random Forest and the feature set RF feature count 120 correlation threshold 0.9\n",
      "\n",
      "Mean accuracy across 5 folds is 0.980\n",
      "Standard Deviation in accuracy across 5 folds is 0.003\n",
      "Mean f1_macro across 5 folds is 0.981\n",
      "Standard Deviation in f1_macro across 5 folds is 0.003\n",
      "\n",
      "Score for Random Forest and the feature set RF feature count 120 correlation threshold 0.95\n",
      "\n",
      "Mean accuracy across 5 folds is 0.981\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.981\n",
      "Standard Deviation in f1_macro across 5 folds is 0.003\n"
     ]
    }
   ],
   "source": [
    "rf_scores = calculate_cross_validation_scores({\"Random Forest\" : rf_model}, random_forest_feature_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55698957",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>We can see that the higheset accuracy is given by 120 feature .95 correlation feature set which is 98.1%.</li>\n",
    "    <li>The accuracies do not differ very much although the number of features increase as we do from top to bottom.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc9f51",
   "metadata": {},
   "source": [
    "Let us also calculate the efficency of the feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1e91f",
   "metadata": {},
   "source": [
    "<b>One thing to be aware of is the feature sets with the lowest number of features yield higher efficency, since the information the model is able to capture after the first few features will be redundant and hence the value added by the first few features cannot be added by the next ones.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8723809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficency per feature for Random Forest RF feature count 80 correlation threshold 0.85 is 38.29\n",
      "Efficency per feature for Random Forest RF feature count 80 correlation threshold 0.9 is 36.78\n",
      "Efficency per feature for Random Forest RF feature count 80 correlation threshold 0.95 is 36.93\n",
      "Efficency per feature for Random Forest RF feature count 100 correlation threshold 0.85 is 28.18\n",
      "Efficency per feature for Random Forest RF feature count 100 correlation threshold 0.9 is 26.71\n",
      "Efficency per feature for Random Forest RF feature count 100 correlation threshold 0.95 is 26.67\n",
      "Efficency per feature for Random Forest RF feature count 120 correlation threshold 0.85 is 25.93\n",
      "Efficency per feature for Random Forest RF feature count 120 correlation threshold 0.9 is 24.66\n",
      "Efficency per feature for Random Forest RF feature count 120 correlation threshold 0.95 is 24.67\n"
     ]
    }
   ],
   "source": [
    "rf_efficiencies = evaluate_model_efficiency(rf_scores, random_forest_feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e014be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_experiment = max(rf_efficiencies, key=rf_efficiencies.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f615e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_efficent_rf_model_id = best_rf_experiment[14:]\n",
    "most_efficent_rf_model_id\n",
    "X_train_efficent_rf = random_forest_feature_sets[most_efficent_rf_model_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d92efe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most efficent model is Random Forest RF feature count 80 correlation threshold 0.85 with 25 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The most efficent model is {best_rf_experiment} with {random_forest_feature_sets[most_efficent_rf_model_id][0].shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c008200",
   "metadata": {},
   "source": [
    "<h3>But with only 25 features, the model might not be able to capture all the patterns and perform bad on the testing set. So let us also consider one more set with higher accuracy, so we can come to a final decision when we do our final testing.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d135e",
   "metadata": {},
   "source": [
    "Looks like our best performing model is RF feature count 120 correlation threshold 0.95, so this will be our other feature set being considered for final testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7ff2977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most accurate model is Random ForestRF feature count 120 correlation threshold 0.95 with 47 features\n"
     ]
    }
   ],
   "source": [
    "most_accurate_rf_model_id = \"RF feature count 120 correlation threshold 0.95\"\n",
    "print(f\"The most accurate model is Random Forest{most_accurate_rf_model_id} with {random_forest_feature_sets[most_accurate_rf_model_id][0].shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be7444",
   "metadata": {},
   "source": [
    "<h2>Finalizing XGBoost feature sets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03dcab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for XGBoost and the feature set XGB feature count 80 correlation threshold 0.85\n",
      "\n",
      "Mean accuracy across 5 folds is 0.988\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.988\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "\n",
      "Score for XGBoost and the feature set XGB feature count 80 correlation threshold 0.9\n",
      "\n",
      "Mean accuracy across 5 folds is 0.989\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.989\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for XGBoost and the feature set XGB feature count 80 correlation threshold 0.95\n",
      "\n",
      "Mean accuracy across 5 folds is 0.990\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.990\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "\n",
      "Score for XGBoost and the feature set XGB feature count 100 correlation threshold 0.85\n",
      "\n",
      "Mean accuracy across 5 folds is 0.987\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.987\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "\n",
      "Score for XGBoost and the feature set XGB feature count 100 correlation threshold 0.9\n",
      "\n",
      "Mean accuracy across 5 folds is 0.987\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.987\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for XGBoost and the feature set XGB feature count 100 correlation threshold 0.95\n",
      "\n",
      "Mean accuracy across 5 folds is 0.989\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.989\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "\n",
      "Score for XGBoost and the feature set XGB feature count 120 correlation threshold 0.85\n",
      "\n",
      "Mean accuracy across 5 folds is 0.990\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.990\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "\n",
      "Score for XGBoost and the feature set XGB feature count 120 correlation threshold 0.9\n",
      "\n",
      "Mean accuracy across 5 folds is 0.990\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.990\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for XGBoost and the feature set XGB feature count 120 correlation threshold 0.95\n",
      "\n",
      "Mean accuracy across 5 folds is 0.990\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.990\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n"
     ]
    }
   ],
   "source": [
    "xgb_scores = calculate_cross_validation_scores({\"XGBoost\" : xgb_model}, xgboost_feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea17c76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficency per feature for XGBoost XGB feature count 80 correlation threshold 0.85 is 26.38\n",
      "Efficency per feature for XGBoost XGB feature count 80 correlation threshold 0.9 is 21.72\n",
      "Efficency per feature for XGBoost XGB feature count 80 correlation threshold 0.95 is 21.79\n",
      "Efficency per feature for XGBoost XGB feature count 100 correlation threshold 0.85 is 21.19\n",
      "Efficency per feature for XGBoost XGB feature count 100 correlation threshold 0.9 is 18.39\n",
      "Efficency per feature for XGBoost XGB feature count 100 correlation threshold 0.95 is 18.46\n",
      "Efficency per feature for XGBoost XGB feature count 120 correlation threshold 0.85 is 18.16\n",
      "Efficency per feature for XGBoost XGB feature count 120 correlation threshold 0.9 is 16.08\n",
      "Efficency per feature for XGBoost XGB feature count 120 correlation threshold 0.95 is 16.08\n"
     ]
    }
   ],
   "source": [
    "xgb_efficiencies = evaluate_model_efficiency(xgb_scores, xgboost_feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0bc7762",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_experiment = max(xgb_efficiencies, key=xgb_efficiencies.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ddcd7fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_efficent_xgb_model_id = best_xgb_experiment[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bba5b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most efficent model is XGBoost XGB feature count 80 correlation threshold 0.85 with 37 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The most efficent model is {best_xgb_experiment} with {xgboost_feature_sets[most_efficent_xgb_model_id][0].shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aced50f",
   "metadata": {},
   "source": [
    "If we look at the results the best accuracy is 99%, which is given 4 different feature sets. So we pick the one with the least number of features, since it can be noted that the additional features did not do any good to the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55607f5c",
   "metadata": {},
   "source": [
    "So we pick Feature count 80 threshold 0.85 for the most accurate one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c4fec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_accurate_xgb_model_id = 'XGB feature count 80 correlation threshold 0.95'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d424e7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most efficent model is XGB feature count 80 correlation threshold 0.95 with 53 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The most efficent model is {most_accurate_xgb_model_id} with {xgboost_feature_sets[most_accurate_xgb_model_id][0].shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80536b",
   "metadata": {},
   "source": [
    "<h3>If we look at both Random Forest and XGBoost models, the feature set with least number of features is often the most efficent one. This is obviously biased towards the feature set with least features if we look at how we are evaluating our model efficency in our evaluate_model_efficiency function.</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349381b0",
   "metadata": {},
   "source": [
    "So this is why selecting another feature set that is highly accurate is also neccesary, so that while testing we do not end up with models that does not perform good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317ed15",
   "metadata": {},
   "source": [
    "<h2>Baseline Establishment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "455656dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feature_sets = {\n",
    "    \"All Features\" : (X_train, y_train),\n",
    "    \"Mean std features\" : (X_train_mean_std, y_train),\n",
    "    \"Anova features\" : (X_train_anova_60, y_train),\n",
    "    \"Most efficent Random Forest features\" : random_forest_feature_sets[most_efficent_rf_model_id],\n",
    "    \"Most accurate Random Forest features\" : random_forest_feature_sets[most_accurate_rf_model_id],\n",
    "    \"Most efficent XGBoost features\" : xgboost_feature_sets[most_efficent_xgb_model_id],\n",
    "    \"Most accurate XGBoost features\" : xgboost_feature_sets[most_accurate_xgb_model_id]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b10f75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_feature_sets['Most efficent Random Forest features'][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55e48c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score for Random Forest and the feature set All Features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.982\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.982\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for Random Forest and the feature set Mean std features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.978\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.978\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for Random Forest and the feature set Anova features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.984\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.984\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for Random Forest and the feature set Most efficent Random Forest features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.978\n",
      "Standard Deviation in accuracy across 5 folds is 0.003\n",
      "Mean f1_macro across 5 folds is 0.978\n",
      "Standard Deviation in f1_macro across 5 folds is 0.003\n",
      "\n",
      "Score for Random Forest and the feature set Most accurate Random Forest features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.981\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.981\n",
      "Standard Deviation in f1_macro across 5 folds is 0.003\n",
      "\n",
      "Score for Random Forest and the feature set Most efficent XGBoost features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.978\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.979\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for Random Forest and the feature set Most accurate XGBoost features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.981\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.981\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "\n",
      "Score for XGBoost and the feature set All Features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.991\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.992\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for XGBoost and the feature set Mean std features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.987\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.987\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "\n",
      "Score for XGBoost and the feature set Anova features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.988\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.989\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for XGBoost and the feature set Most efficent Random Forest features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.984\n",
      "Standard Deviation in accuracy across 5 folds is 0.002\n",
      "Mean f1_macro across 5 folds is 0.984\n",
      "Standard Deviation in f1_macro across 5 folds is 0.002\n",
      "\n",
      "Score for XGBoost and the feature set Most accurate Random Forest features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.987\n",
      "Standard Deviation in accuracy across 5 folds is 0.004\n",
      "Mean f1_macro across 5 folds is 0.988\n",
      "Standard Deviation in f1_macro across 5 folds is 0.004\n",
      "\n",
      "Score for XGBoost and the feature set Most efficent XGBoost features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.988\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.988\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "\n",
      "Score for XGBoost and the feature set Most accurate XGBoost features\n",
      "\n",
      "Mean accuracy across 5 folds is 0.990\n",
      "Standard Deviation in accuracy across 5 folds is 0.001\n",
      "Mean f1_macro across 5 folds is 0.990\n",
      "Standard Deviation in f1_macro across 5 folds is 0.001\n",
      "Efficency per feature for Random Forest All Features is 1.72\n",
      "Efficency per feature for Random Forest Mean std features is 14.49\n",
      "Efficency per feature for Random Forest Anova features is 8.28\n",
      "Efficency per feature for Random Forest Most efficent Random Forest features is 38.29\n",
      "Efficency per feature for Random Forest Most accurate Random Forest features is 20.47\n",
      "Efficency per feature for Random Forest Most efficent XGBoost features is 25.88\n",
      "Efficency per feature for Random Forest Most accurate XGBoost features is 18.16\n",
      "Efficency per feature for XGBoost All Features is 1.75\n",
      "Efficency per feature for XGBoost Mean std features is 14.76\n",
      "Efficency per feature for XGBoost Anova features is 8.35\n",
      "Efficency per feature for XGBoost Most efficent Random Forest features is 38.75\n",
      "Efficency per feature for XGBoost Most accurate Random Forest features is 20.75\n",
      "Efficency per feature for XGBoost Most efficent XGBoost features is 26.38\n",
      "Efficency per feature for XGBoost Most accurate XGBoost features is 18.50\n"
     ]
    }
   ],
   "source": [
    "final_scores = calculate_cross_validation_scores(models, final_feature_sets)\n",
    "final_efficiencies = evaluate_model_efficiency(final_scores, final_feature_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa4848",
   "metadata": {},
   "source": [
    "<b>There are a few things we can infer from the results</b>\n",
    "<ul>\n",
    "    <li>\n",
    "        The feature set with the highest accuracy is the model which is trained on all the features and XGBoost. <b>This will be out baseline model.</b></li>\n",
    "    <li>But the most efficent model we have is the XGBoost model trained on feature set that is extracted from Random Forest feature importances which has 25 features in it with an efficency value of 38.75. This is a massive reduction in features almost a 95% but just a loss of 0.7% accuracy</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f726038c",
   "metadata": {},
   "source": [
    "<b>So here are the feature sets we are going to perform hyper parameter tuning and evaluating final results</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e072a4",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>All Features</li>\n",
    "    <li>Research Benchmark (Mean/Std) features</li>\n",
    "    <li>XGBoost most accurate set</li>\n",
    "    <li>Random Forest most efficent set</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e549475",
   "metadata": {},
   "source": [
    "We have the first 2 sets already, but we need to export the XGBoost most accurate set and Random Forest most efficent set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c05ecf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_most_accurate_train = xgboost_feature_sets[most_accurate_xgb_model_id][0]\n",
    "xgb_most_accurate_test = X_test[xgb_most_accurate_train.columns]\n",
    "rf_most_efficent_train = random_forest_feature_sets[most_efficent_rf_model_id][0]\n",
    "rf_most_efficent_test = X_test[rf_most_efficent_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e249d6",
   "metadata": {},
   "source": [
    "<b>Exporting the feature sets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "880093a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_most_accurate_train.to_csv(\"../Final Feature Sets/xgb_most_accurate_train.csv\")\n",
    "xgb_most_accurate_test.to_csv(\"../Final Feature Sets/xgb_most_accurate_test.csv\")\n",
    "rf_most_efficent_train.to_csv(\"../Final Feature Sets/rf_most_efficent_train.csv\")\n",
    "rf_most_efficent_test.to_csv(\"../Final Feature Sets/rf_most_efficent_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b272e0d",
   "metadata": {},
   "source": [
    "Now onto our Final journey with XGBoost <b>Hyper Parameter Tuning and Evaluation</b>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
